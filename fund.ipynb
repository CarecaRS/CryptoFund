{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "179c5bcb",
   "metadata": {},
   "source": [
    "## To-do list\n",
    "- metrics functions\n",
    "- check for directories structure (model for prediction, databases, saving directory for the drawdown/VaR/etc plots, backup directory for model, backup directory for plots)\n",
    "- import metrics (VaR, cVaR, drawdown, etc.) functions from metrics.py\n",
    "- Binance access and etc (copy from Touring)\n",
    "- Copy keys.py explanation from Touring\n",
    "- Two main fund strategies: (1) passive - trade on 1st of each month, keep in basked the 10 crytpos with the most market cap; (2) active - trade every week based on predicted returns for the next week\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fefab3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------ Import basic packages\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#import smtplib  # Needed for the e-mail reports\n",
    "#import binance.enums  # Responsible for trading\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta\n",
    "from keys import api_secret_offline, api_key_offline  # These are your infos, read the README.md if you're lost here\n",
    "pd.set_option('display.float_format', lambda x: '%.8f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bd8382e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "\n",
    "#------ Binance access\n",
    "def binance_wallet(live_trade=False):\n",
    "    \"\"\"\n",
    "    Description: function that fetches Binance balance for the user\n",
    "\n",
    "    Inputs: live_trade - bool, default False. If True checks for live trade ability (not needed for backtesting)\n",
    "    \n",
    "    Outputs objects: wallet - pd.DataFrame, existing assets and balances\n",
    "                    cliente - object, binance.client.Client (EXCLUDED FROM return)\n",
    "                    infos - dict, overall informations about the client (EXCLUDED FROM return)\n",
    "    \"\"\"\n",
    "    # Necessary packages\n",
    "    import pandas as pd\n",
    "    from binance.client import Client  # Binance\n",
    "\n",
    "    def request_wallet():\n",
    "            # Requests user wallet infos\n",
    "            print('Fetching wallet balance...')\n",
    "            wallet = pd.DataFrame(infos['balances'])\n",
    "\n",
    "            # Gets the 'numerical' informations about the balances\n",
    "            nums = ['free', 'locked']\n",
    "\n",
    "            # Transform objs in float\n",
    "            wallet[nums] = wallet[nums].astype(float)\n",
    "\n",
    "            # Filter the assets with balance\n",
    "            mask = wallet[nums][wallet[nums] > 0].dropna(how='all').index\n",
    "            print('Cleaning wallet from non-positive cryptos...')\n",
    "            wallet = wallet.iloc[mask]  # keep only assets with positive balance\n",
    "\n",
    "            # If needed, excludes some cryptos (asset blacklisting)\n",
    "            black_list = ['NFT', 'SHIB', 'BTTC']\n",
    "            mask = wallet[wallet['asset'].isin(black_list)].index  # blacklist index\n",
    "            wallet.drop(mask, axis=0, inplace=True)  # dropping blacklist\n",
    "            print('Done.')\n",
    "\n",
    "            print(f'\\n--> Please note this account type: {infos['accountType']} <--')\n",
    "\n",
    "            wallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            return wallet\n",
    "    \n",
    "    # Get overall info from Binance, using offline (not live) keys\n",
    "    cliente = Client(api_key_offline, api_secret_offline)\n",
    "\n",
    "    # Checks for systems online\n",
    "    if cliente.get_system_status()['msg'] != 'normal':\n",
    "        print('\\n\\n!!!! **** WARNING **** !!!!\\n')\n",
    "        print('!!!! BINANCE OFFLINE !!!!\\n')\n",
    "        print('Unable to fetch data\\n\\n')\n",
    "\n",
    "    else:\n",
    "        print('\\nBinance on-line. Requesting data.')\n",
    "        # Fetch user data\n",
    "        infos = cliente.get_account()\n",
    "\n",
    "        if live_trade == True:\n",
    "            # Check if the user is able to live trade (not mandatory for offline)\n",
    "            if infos['canTrade'] == False:\n",
    "                print('\\nWARNING! User unable to trade, please check status with Binance!')\n",
    "                print('Aborting.')\n",
    "            else:\n",
    "                wallet = request_wallet()\n",
    "\n",
    "        else:\n",
    "            wallet = request_wallet()\n",
    "    \n",
    "    return wallet\n",
    "\n",
    "\n",
    "#------ Historical data\n",
    "def historical_data(ticker='BTCUSDT', days=30, interval='15m'):  # the ticker in Binance works in pairs - here you'll want to know how much is BTC worth in USDT, for example\n",
    "    \"\"\"\n",
    "    Description: gets the trading pair historical data from Binance.\n",
    "\n",
    "    Inputs: ticker - str, default 'BTCUSDT', the pair you want to trade;\n",
    "            days - int, default 30, gets historical data from this many days ago;\n",
    "            interval - str, default '15m', the 'slicing' of the timeframe, more info at https://developers.binance.com/docs/binance-spot-api-docs/web-socket-streams#klinecandlestick-streams-for-utc\n",
    "    \n",
    "    Outputs objects: hist - pd.DataFrame, OHLC historical data\n",
    "    \"\"\"\n",
    "    import datetime\n",
    "    import requests\n",
    "    import json\n",
    "    import time\n",
    "    import pandas as pd\n",
    "\n",
    "    # Defines the data timespan\n",
    "    end_time = datetime.datetime.now()\n",
    "    start_time = end_time - datetime.timedelta(days=days)\n",
    "    \n",
    "    # Converts time to Unix (because Binance) in miliseconds\n",
    "    end_timestamp = int(end_time.timestamp()*1000)\n",
    "    start_timestamp = int(start_time.timestamp()*1000)\n",
    "\n",
    "    # Binance endpoint\n",
    "    endpoint = 'https://api.binance.com/api/v3/klines'\n",
    "\n",
    "    # Timewindow estabilished, requests historical data.\n",
    "    # Request parameters.\n",
    "    limit = 1000\n",
    "    params = {'symbol': ticker, 'interval': interval,\n",
    "          'endTime': end_timestamp, 'limit': limit,\n",
    "          'startTime': start_timestamp}\n",
    "    print('Requesting informations from Binance.')\n",
    "\n",
    "    # Make the request and saves it in a list. 'Dados' means 'data' in portuguese.\n",
    "    dados = []\n",
    "    while True:\n",
    "        response = requests.get(endpoint, params=params)\n",
    "        klines = json.loads(response.text)\n",
    "        dados += klines\n",
    "        if len(klines) < limit:\n",
    "            break\n",
    "        params['startTime'] = int(klines[-1][0])+1\n",
    "        time.sleep(0.1)\n",
    "    print('Request successful. Splitting data...')\n",
    "\n",
    "    # Pick specific data from fetched data\n",
    "    # About kline[n] pos: https://developers.binance.com/docs/binance-spot-api-docs/rest-api/market-data-endpoints\n",
    "    loose_data = []\n",
    "    for kline in dados:\n",
    "        loose_data = [[float(kline[1]), float(kline[2]), float(kline[3]), float(kline[4]), float(kline[5])] for kline in dados]\n",
    "\n",
    "    # Creates the DataFrame\n",
    "    timestamps = [datetime.datetime.fromtimestamp(int(kline[0])/1000) for kline in dados]\n",
    "    hist = pd.DataFrame(loose_data, columns=['open', 'high', 'low', 'close', 'volume'], index=timestamps)\n",
    "    hist = pd.concat([hist], keys=[ticker], names=['asset', 'time'])\n",
    "\n",
    "    print('All done.')\n",
    "\n",
    "    return hist\n",
    "\n",
    "\n",
    "#------ Check for trading pairs CSV file\n",
    "def check_pairs():\n",
    "    \"\"\"\n",
    "    Description: checks if there's a trading pairs record, makes up the trading pairs from Binance toAsset and fromAsset data if none is found\n",
    "    Inputs: none\n",
    "    Outputs: none (generates a csv file though)\n",
    "    \"\"\"\n",
    "    import datetime\n",
    "    import requests\n",
    "    import json\n",
    "    import os\n",
    "    import pandas as pd\n",
    "\n",
    "    # Stores current month and year, used to validate files\n",
    "    today = datetime.datetime.now().strftime('%Y%m')\n",
    "    \n",
    "    # Resources and backup path\n",
    "    resources_dir = './resources/'\n",
    "    backup_dir = 'older_versions/'\n",
    "\n",
    "    #------ List with the 20 top market cap currencies\n",
    "    def top20():\n",
    "        \"\"\"\n",
    "        Description: get the 20 biggest market cap cryptos from the web. Needs tweaks for each source.\n",
    "\n",
    "        input: none\n",
    "\n",
    "        outpu: list, cryptocurrencies symbols\n",
    "        \"\"\"\n",
    "        import requests\n",
    "        from bs4 import BeautifulSoup\n",
    "\n",
    "        cmc = 'https://crypto.com/price'\n",
    "        \n",
    "        print('Getting list of the 20 cryptos with the most market cap.')\n",
    "\n",
    "        try:\n",
    "            response = requests.get(cmc)\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "            site = soup.find_all(\"span\", {\"class\": \"chakra-text\"})\n",
    "\n",
    "            cryptos = []\n",
    "            for cur in site:\n",
    "                cryptos.append(cur.get_text())\n",
    "            \n",
    "            print('Done.')\n",
    "        \n",
    "        except:\n",
    "            print(f\"Error fetching biggest market cap cryptos from {cmc}\")\n",
    "        \n",
    "        return cryptos[0:20]\n",
    "\n",
    "\n",
    "    #------ Creates the buy/sell pairs from Binance endpoint\n",
    "    def create_pairs_file():\n",
    "        # Sets Binance endpoint and its parameter (crypto common to all trades, in this case)\n",
    "        pairs_endpoint = 'https://api.binance.com/sapi/v1/convert/exchangeInfo'\n",
    "        params = {'toAsset': 'USDT'}\n",
    "\n",
    "        # Fetches the Top 20 market cap cryptos from the web to make our asset basket\n",
    "        crypto_list = top20()\n",
    "\n",
    "        # Makes the request\n",
    "        print('Retrieving information about pairing trades from Binance.')\n",
    "        response = requests.get(pairs_endpoint, params=params)\n",
    "        \n",
    "        # Changes the response into a DataFrame\n",
    "        df = pd.DataFrame(json.loads(response.text))\n",
    "\n",
    "        # Filters Binance cryptos data maintaining only the top 20 at most\n",
    "        print('Filtering all assets not tradable from Binance.')\n",
    "        mask = df['fromAsset'].isin(crypto_list)\n",
    "        df = df.loc[mask].reset_index(drop=True)\n",
    "\n",
    "        # Creates the buy/sell pairs\n",
    "        print('Registering tradable pairs.')\n",
    "        sell_pairs = df['fromAsset'] + df['toAsset']\n",
    "        buy_pairs = df['toAsset'] + df['fromAsset']\n",
    "\n",
    "        # Creates a new temp DataFrame with just the pairs\n",
    "        temp = pd.concat([buy_pairs, sell_pairs], axis=1)\n",
    "        temp.columns = ['Buy', 'Sell']\n",
    "\n",
    "        # Saves to file\n",
    "        print('Creating new file...')\n",
    "        temp.to_csv(f'{resources_dir}pairs_{today}.csv', index=False)\n",
    "        print(f\"Trading pairs file created: '{resources_dir}pairs_{today}.csv'\")\n",
    "        print('All done.')        \n",
    "\n",
    "    # Checks for path\n",
    "    if not os.path.exists(resources_dir):\n",
    "        print(f\"Directory '{resources_dir}' does not exist. Let's make it, shall we?\")\n",
    "        os.mkdir(resources_dir)\n",
    "        print(f\"Done, directory '{resources_dir}' created successfully.\")\n",
    "    \n",
    "    else:\n",
    "        print('The resources directory exists, checking for trade pairs file.')\n",
    "\n",
    "    # Check for any pair file. If it exists and is newer than a month, loads it.\n",
    "    arqs = os.listdir(resources_dir)\n",
    "\n",
    "    # Keeps only generated files, disregarding folders or other misc files\n",
    "    for i in arqs:\n",
    "        if 'pairs' not in str(i):\n",
    "            arqs.remove(i)\n",
    "\n",
    "    if len(arqs) == 0:\n",
    "        print('Trading file not found in folder. Creating...')\n",
    "        create_pairs_file()\n",
    "\n",
    "    elif len(arqs) == 1:\n",
    "        arqs = arqs[0]\n",
    "        print(f\"Trading pairs file '{arqs}' found, checking version.\")\n",
    "        file_found = arqs.split('.csv')[0]\n",
    "        file_found = file_found.split('_')[1]\n",
    "\n",
    "        if int(today) > int(file_found):\n",
    "            import shutil                        \n",
    "            print(f\"Time to update the files! Moving current file to './{backup_dir}'.\")\n",
    "            shutil.move(resources_dir+arqs, resources_dir+backup_dir+arqs)\n",
    "            print(f'Updating trading pairs file.')\n",
    "            create_pairs_file()\n",
    "\n",
    "        else:\n",
    "            print('Trading pairs file is up to date.')\n",
    "\n",
    "    elif len(arqs) > 1:\n",
    "        print(f\"WARNING: Multiple files found! Moving all trading pairs files to './{backup_dir}'.\")\n",
    "        for i in arqs:\n",
    "            import shutil\n",
    "            shutil.move(resources_dir+i, resources_dir+backup_dir+i)\n",
    "        print(f'Creating valid trading pairs file.')\n",
    "        create_pairs_file()\n",
    "    \n",
    "    else:\n",
    "        print(\"Some kind of witchcraft error happened. This message isn't supposed to show up!\")\n",
    "\n",
    "\n",
    "#------ Loads the trading pairs CSV file\n",
    "def get_pairs():\n",
    "    \"\"\"\n",
    "    Description: loads the latest trading pairs file using pandas.read_csv()\n",
    "\n",
    "    Input: none\n",
    "    Output: pandas.DataFrame\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import pandas as pd\n",
    "\n",
    "    resources_dir = './resources/'\n",
    "\n",
    "    # Check for the pairs file.\n",
    "    arqs = os.listdir(resources_dir)\n",
    "\n",
    "    # Keeps only generated files, disregarding folders or other misc files\n",
    "    for i in arqs:\n",
    "        if 'pairs' not in str(i):\n",
    "            arqs.remove(i)\n",
    "\n",
    "    if len(arqs) == 0:\n",
    "        print('ERROR: Trading file not found in folder. Please run check_pairs() first.')\n",
    "\n",
    "    elif len(arqs) == 1:\n",
    "        arqs = arqs[0]\n",
    "        pairs = pd.read_csv(f'{resources_dir}{arqs}')\n",
    "\n",
    "    elif len(arqs) > 1:\n",
    "        print(f\"ERROR: Multiple files found! Please run check_pairs() first.\")\n",
    "\n",
    "    return pairs\n",
    "\n",
    "\n",
    "#------ ATR indicator estimation\n",
    "def atr_calc(df, length=20):\n",
    "    \"\"\"\n",
    "    Description: function to compute Average True Range estimations.\n",
    "    Important Notice: df MUST have 'high', 'low', 'close' values features.\n",
    "\n",
    "    Input: df, OHLC pandas DataFrame\n",
    "    Output: pandas Series, with standardized ATR\n",
    "    \"\"\"\n",
    "    import pandas_ta\n",
    "\n",
    "    atr = pandas_ta.atr(high=df['high'],\n",
    "                        low=df['low'],\n",
    "                        close=df['close'],\n",
    "                        length=length)\n",
    "    \n",
    "    return atr.sub(atr.mean()).div(atr.std())\n",
    "\n",
    "\n",
    "#------ MACD estimation\n",
    "def macd_calc(df, length=30):\n",
    "    \"\"\"\n",
    "    Description: custom function to estimate MACD indicator\n",
    "    Inputs: df, OHLC pandas DataFrame\n",
    "    Outputs: indicator estimated\n",
    "    \"\"\"\n",
    "    import pandas_ta\n",
    "\n",
    "    macd = pandas_ta.macd(close=df['close'], length=length)\n",
    "\n",
    "    return macd.sub(macd.mean()).div(macd.std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a430cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from metrics import mvcriterion, optim_mvcrit\n",
    "\n",
    "#wallet = binance_wallet()\n",
    "\n",
    "# First of all, fetch pairs file\n",
    "try:\n",
    "    print('Loading trading pairs...')\n",
    "    pairs = get_pairs()\n",
    "    print('Pairs successfully loaded.')\n",
    "except:\n",
    "    check_pairs()\n",
    "    print('Loading trading pairs...')\n",
    "    pairs = get_pairs()\n",
    "    print('Pairs successfully loaded.')\n",
    "\n",
    "# Then, get the historical data from Binance\n",
    "# Params\n",
    "pool = pd.DataFrame()\n",
    "past_days = 365\n",
    "interv = '1d'\n",
    "\n",
    "for asset in pairs['Sell']:\n",
    "    temp = historical_data(ticker=asset, days=past_days, interval=interv)\n",
    "    pool = pd.concat([pool, temp])\n",
    "    del temp\n",
    "\n",
    "# Up until here I've got a 'pool' object with the historical data and my trading pairs file loaded into 'pairs' object.\n",
    "# Let's calculate some indicators now\n",
    "\n",
    "# Calculating Relative Strenght Index (RSI) - momentum indicator\n",
    "# The RSI indicator won't be standardized for its use in clustering\n",
    "pool['rsi'] = pool.groupby(level=0)['close'].transform(lambda x: pandas_ta.rsi(close=x, length=20))\n",
    "#pool.xs('BTCUSDT', level=0)['rsi'].plot() # to check if it's worked just uncomment the beginning of this line\n",
    "\n",
    "# Calculating Bollinger Bands - volatility indicator (overbought/oversold)\n",
    "pool['bb_low'] = pool.groupby(level=0)['close'].transform(lambda x: pandas_ta.bbands(close=np.log1p(x), length=20).iloc[:,0])\n",
    "pool['bb_mid'] = pool.groupby(level=0)['close'].transform(lambda x: pandas_ta.bbands(close=np.log1p(x), length=20).iloc[:,1])\n",
    "pool['bb_high'] = pool.groupby(level=0)['close'].transform(lambda x: pandas_ta.bbands(close=np.log1p(x), length=20).iloc[:,2])\n",
    "\n",
    "# Average True Range (ATR) - volatility indicator\n",
    "# Since this function uses 3 features to compute the indicator (high, low, close), it is needed to use 'apply' instead of 'transform',\n",
    "# and for that a custom function is needed (check it in Functions section).\n",
    "pool['atr'] = pool.groupby(level=0, group_keys=False).apply(atr_calc)\n",
    "\n",
    "# Moving Average Convergence-Divergence (MACD) - momentum indicator\n",
    "# Same reasonig as ATR, a custom function is needed here.\n",
    "pool['macd'] = pool.groupby(level=0, group_keys=False).apply(macd_calc).iloc[:,0]\n",
    "\n",
    "# Dollar volume (based on closing price), divided by 1M\n",
    "pool['dollar_vol'] = pool['volume']*pool['close']/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d51cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indicators['rsi'] = indicators.groupby(level=0)['close'].transform(lambda x: pandas_ta.rsi(close=x, length=30))\n",
    "#indicators['bb_low'] = indicators.groupby(level=0)['close'].transform(lambda x: pandas_ta.bbands(close=np.log1p(x), length=30).iloc[:,0])\n",
    "#indicators['bb_mid'] = indicators.groupby(level=0)['close'].transform(lambda x: pandas_ta.bbands(close=np.log1p(x), length=30).iloc[:,1])\n",
    "#indicators['bb_high'] = indicators.groupby(level=0)['close'].transform(lambda x: pandas_ta.bbands(close=np.log1p(x), length=30).iloc[:,2])\n",
    "#indicators['atr'] = indicators.groupby(level=0, group_keys=False).apply(atr_calc)\n",
    "#indicators['macd'] = indicators.groupby(level=0, group_keys=False).apply(macd_calc).iloc[:,0]\n",
    "#indicators['dollar_vol'] = indicators['volume']*indicators['close']/1e6\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#############################(parei em ~37min do video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5737667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators['dollar_vol'] = indicators['volume']*indicators['close']/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5b1b0fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6166.00000000\n",
       "mean      441.21599694\n",
       "std       817.78448058\n",
       "min         0.44324074\n",
       "25%        31.36059916\n",
       "50%       109.55678061\n",
       "75%       475.62390091\n",
       "max     10656.43133277\n",
       "Name: dollar_vol, dtype: float64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicators['dollar_vol'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "326faa01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting informations from Binance.\n",
      "Request successful. Splitting data...\n"
     ]
    }
   ],
   "source": [
    "ticker = 'BTCUSDT'\n",
    "interval = '1d'\n",
    "days = 180\n",
    "\n",
    "try:\n",
    "    import datetime\n",
    "    import requests\n",
    "    import json\n",
    "    import time\n",
    "    import pandas as pd\n",
    "\n",
    "    # Defines the data timespan\n",
    "    end_time = datetime.datetime.now()\n",
    "    start_time = end_time - datetime.timedelta(days=days)\n",
    "    \n",
    "    # Converts time to Unix (because Binance) in miliseconds\n",
    "    end_timestamp = int(end_time.timestamp()*1000)\n",
    "    start_timestamp = int(start_time.timestamp()*1000)\n",
    "\n",
    "    # Binance endpoint\n",
    "    endpoint = 'https://api.binance.com/api/v3/klines'\n",
    "\n",
    "    # Timewindow estabilished, requests historical data.\n",
    "    # Request parameters.\n",
    "    limit = 1000\n",
    "    params = {'symbol': ticker, 'interval': interval,\n",
    "          'endTime': end_timestamp, 'limit': limit,\n",
    "          'startTime': start_timestamp}\n",
    "    print('Requesting informations from Binance.')\n",
    "\n",
    "    # Make the request and saves it in a list. 'Dados' means 'data' in portuguese.\n",
    "    dados = []\n",
    "    while True:\n",
    "        response = requests.get(endpoint, params=params)\n",
    "        klines = json.loads(response.text)\n",
    "        dados += klines\n",
    "        if len(klines) < limit:\n",
    "            break\n",
    "        params['startTime'] = int(klines[-1][0])+1\n",
    "        time.sleep(0.1)\n",
    "    print('Request successful. Splitting data...')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'Algo deu de errado: {e}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
